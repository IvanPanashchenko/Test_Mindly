Для проведення аналізу тексту вирішив використати такі бібліотеки як SpaCy, NLTK та модель LDA(Latent Dirichlet Allocation).
Так як кожен підхід мав різний результат, я вирішив викласти одразу дві версії виконання.

Mindly_Test_1_version 
Спершу перетворення тексту на Bag-of-words. Це спрощений метод визначення тем у документі. Він працює на припущенні, що чим вище частота терміна, тим вище його важливість. Далі Text Preprocessing. Результати згенеровані за допомогою Bag-of-words, є цікавими, але не корисними. Це пов’язано з тим, що такі лексеми, як «ну» та «типо», є звичайними словами і не дуже допомагають у визначенні тем. Щоб подолати це, ми виконаємо попередню обробку тексту. Після чого використовуємо Gensim-NLP та LDA для перетворення слів у вектори. Саме багатовимірні матриці векторів дають нам уявлення про взаємозв’язки між термінами у тексті. Першим кроком є перетворення тексту в матричне представлення, після чого створення об’єкта моделі LDA та наступне її навчання на матриці. У наведених результатах кожен рядок представляє тему з окремими термінами  та їх вагою, але вони  вийшли у мене нечитабельні. Хоча увесь підхід, на мою думку, був правильний, тому вирішив по іншому вирішити завдання.

Mindly_Test_2_version 
Бібліотека SpaCy дуже проста у плані вирішення задач, має вже претренеровані пайплайни а також претренерований механізм word to vectors. Єдина проблема з якою я стикнувся, це "en_core_web_lg", але, на диво, вона чудово спрацювала і для тексту російською мовою. 
Ще один плюс-це робота з текстом, яку можна помістити у змінну, тобто не треба перетворювати текст у таблицю csv. Змінюючи значення у "limit_phrases=7, limit_sentences=3", ми можемо отримати більш розширенне резюме тексту. phrases_and_ranks[:10] дає нам інформацію про увесь текст лише 10 фразами.


