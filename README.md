Для проведення аналізу тексту, вирішив використати такі бібліотеки як SpaCy, NLTK та LDA(Latent Dirichlet Allocation ). 
Так як кожний підхід мав різний результат, то я вирішив викласти одразу дві версії виконання.

Mindly_Test_1_version
Bag-of-words, це спрощений метод визначення тем у документі. Він працює на припущенні, що чим вище частота терміна, тим вище його важливість. Далі Text Preprocessing Результати, згенеровані за допомогою Bag-of-words, є цікавими, але не корисними з метою визначення теми. Це пов’язано з тим, що такі лексеми, як «ну» та «типо», є звичайними словами і не дуже допомагають у визначенні тем. Щоб подолати це, ми виконаємо попередню обробку тексту. Після чого використовуємо Gensim-NLP та LDA, використовуються для перетворення слів у вектори. Тобто багатовимірні математичні уявлення слів, дають нам уявлення про взаємозв’язки між термінами у тексті. Першим кроком є перетворення тексту в матричне представлення, після чого створення об’єкта моделі LDA та наступне її навчання  на матриці термінів.
У наведених результатах кожен рядок представляє тему з окремими термінами теми та вагою термінів, але ці терміни вийшли у мене не читабельні.Хоча увесь підхід, на мою думку, був правильний я вирішив по іншому вирішити завдання.




Mindly_Test_2_version
Бібліотека SpaCy дуже проста у плані вирішення задач, має вже пре-тренеровані пайплайни а також пре-тренерований механізм word to vectors.
Едина проблема з якою я стикнувся, це "en_core_web_lg", але на диво, вона чудово спрацювала ы для росыйського тексту. Ще один Плюс- це робота з текстом, яку можна помістити у змінну, не треба перетворювати текст у таблицю csv.
А змінюючи значення у "limit_phrases=7, limit_sentences=3" ми можемо отримати більш розширенне резюме тексту. А phrases_and_ranks[:10] дає нам інформацію про увесь текст лише 10 фразами.


